# -*- coding: utf-8 -*-
"""player_performance_index.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x-YPS2EbTtd4PY6ZIzbQZQfbuZ7E-6Rl

# Requirements
"""

"""# Google Drive Connection"""

#from google.colab import drive
#drive.mount('/content/drive/')

"""# Libraries"""

import pickle

import numpy as np
import pandas as pd

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression

import anvil.server

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import psycopg2
import sqlalchemy
from sqlalchemy.sql import text
import urllib.parse
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

"""# Data"""

df = pd.read_excel('./DataBasis/Statistics.xlsx', sheet_name = 'Hoja 1')
#df.info()
#df

"""# Simulated Data"""

path = './Checkpoints/'
tuple_inputs = pickle.load(open(path + "PreparedDataFrame", 'rb'))
df_sim = tuple_inputs

df_sim.info()
df_sim

"""# Weights"""

df_b = pd.read_excel('./DataBasis/Importance Weights.xlsx', sheet_name = 'Hoja 4')
#df_b.info()
#df_b

"""# Data Cleaning"""

def data_cleaning_weights(df_b):

    df_b.columns = df_b.columns.str.replace(' ', '')
    #df_b = df_b.drop(labels = 'CleanSheets', axis = 'columns')

    return df_b

df_b = data_cleaning_weights(df_b)

df_b

def data_cleaning(df_):

  df_.columns = df_.columns.str.replace(' ', '')
  df_['PT-PlayingTime'] = df_['PT-PlayingTime'].apply(lambda x : float(x[:-1]))
  df_['M-MatchID'] = df_['M-MatchID'].astype(str)

  return df_

#df_x = data_cleaning(df)

"""# Data Preparation"""

def data_sim_preparation(df_):

  # Binary Target

  bin_label = 'OUT-Outcomes'
  df_[bin_label] = np.where(df_[bin_label] == 'W', 1, 0)


  # Target at the end (ReOrder)

  df_ = df_[[c for c in df_ if c != 'OUT-Outcomes'] + ['OUT-Outcomes']]

  return df_

def data_preparation(df_):

  # Binary Target

  bin_label = 'OUT-Outcomes'
  df_[bin_label] = np.where(df_[bin_label] == 'W', 1, 0)

  # One-Hot Encoding to convert categorical non-ordered variables into binary

  nord_labels = ['M-MatchID']

  df_bin = df_[nord_labels]
  df_bin = pd.get_dummies(df_bin)
  df_ = pd.concat([df_, df_bin], axis = 'columns')

  # Target at the end (ReOrder)

  df_ = df_[[c for c in df_ if c != 'OUT-Outcomes'] + ['OUT-Outcomes']]

  return df_

#data_preparation(df)

"""# Pre Processing"""

def data_scaling(df__):

  #print(df__.columns)

  scaler = MinMaxScaler()
  df_vals = df__[['PT-PlayingTime', 'G-Goals', 'A-Assists', 'KP-KeyPasses',
       'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets', 'O-Offsides', 'OUT-Outcomes']]#df__.drop(labels = ['Name', 'P-Profile', 'M-MatchID'], axis = 'columns')
  
  #print(df_vals.columns)
  df_scaled = scaler.fit_transform(df_vals)

  df_ = pd.DataFrame(data = df_scaled, columns = ['PT-PlayingTime', 'G-Goals', 'A-Assists', 'KP-KeyPasses',
       'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets', 'O-Offsides', 'OUT-Outcomes'])
  
  df_['P-Profile'] = df__['P-Profile']

  return df_

#data_scaling(data_preparation(data_cleaning(df))).columns

#data_cleaning_weights(df_b).columns

"""# Model"""

def ppi_model(df_, df_b):

  df_b = df_b[['P-Profile', 'PT-PlayingTime', 'G-Goals', 'A-Assists', 'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball', 'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots','SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls', 'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets','O-Offsides', 'OUT-Outcomes']]
  df__ = df_[['P-Profile', 'PT-PlayingTime', 'G-Goals', 'A-Assists', 'KP-KeyPasses','CP-CompletedPassees', 'SR-SuccessfulRatew/Ball','PP-PossessionParticipation%', 'T-Touches', 'SH-Shots','SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls','YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets','O-Offsides','OUT-Outcomes']]

  df_ = data_scaling(df__)

  ppis = []

  for i in range(0, df_.shape[0]):

    if(df_['P-Profile'][i] == 'Attacker'):

      bethas = df_b[df_b['P-Profile'] == 'Attacker'].drop(labels = 'P-Profile', axis = 'columns').values
      variables =  df_.drop(labels = 'P-Profile', axis = 'columns').iloc[i].values

    elif(df_['P-Profile'][i] == 'Defender'):

      bethas = df_b[df_b['P-Profile'] == 'Defender'].drop(labels = 'P-Profile', axis = 'columns').values
      variables =  df_.drop(labels = 'P-Profile', axis = 'columns').iloc[i].values

    elif(df_['P-Profile'][i] == 'Midfielder'):

      bethas = df_b[df_b['P-Profile'] == 'Midfielder'].drop(labels = 'P-Profile', axis = 'columns').values
      variables =  df_.drop(labels = 'P-Profile', axis = 'columns').iloc[i].values
    
    else: # Goalkeeper

      bethas = df_b[df_b['P-Profile'] == 'Goalkeeper'].drop(labels = 'P-Profile', axis = 'columns').values
      variables =  df_.drop(labels = 'P-Profile', axis = 'columns').iloc[i].values

    ppi = np.dot(bethas, variables) 

    ppis.append(ppi)

  scaler = MinMaxScaler()
  PPI = scaler.fit_transform(np.array(ppis).reshape(-1, 1)).flatten()
  df_['PPI'] = PPI
  df__['PPI'] = PPI

  return df__

#ppi_model(data_preparation(data_cleaning(df)), df_b)

"""# Full Output"""

def add_tags(df_):

  df_['Name'] = df['Name']
  df_['Profile'] = df['P-Profile']
  df_['MatchID'] = df['M-MatchID']
  #df_['OUT-Outcomes'] = df['OUT-Outcomes']

  df_ = df_[[c for c in df_ if c != 'OUT-Outcomes'] + ['OUT-Outcomes']]

  first_column = df_.pop('Name')
  df_.insert(0, 'Name', first_column)

  df_ = df_[[c for c in df_ if c != 'PPI'] + ['PPI']]

  return df_

def ranking(df):

  df_ = df
  df__ = df_.groupby(['Name']).mean().reset_index(drop = False)
  df__['Profile'] = [df_[df_['Name'] == name]['Profile'].unique()[0] for name in df__['Name']]
  df__ = df__.sort_values(by = 'PPI', axis = 'index', ascending = False).reset_index(drop = False).drop(labels = 'index', axis = 'columns').reset_index(drop = False).rename(columns = {'index':'Rank'})
  df__['Rank'] = df__['Rank'].apply(lambda x: x+1)

  return df__

def output(df_):

  df_ = df_[['Name', 'Profile', 'PPI', 'Rank']]

  return df_

"""# Checkpoint Pickle"""

def checkpoint(df, df_sim, df_b, df_output):

  path = './Checkpoints/'
  tuple_inputs = (df, df_sim, df_b, df_output)
  pickle.dump(tuple_inputs, open (path + "ppi_output", 'wb'))

"""# Main"""

def main(df, df_sim, df_b):

  df_b = data_cleaning_weights(df_b)

  df = data_cleaning(df)
  df = data_preparation(df)
  #df = data_scaling(df)
  df = ppi_model(df, df_b)
  df = add_tags(df)
  df = ranking(df)

  df_output = output(df)

  df_sim = data_sim_preparation(df_sim)
  #df_sim = data_scaling(df_sim)
  df_sim = ppi_model(df_sim, df_b)
  df_sim = add_tags(df_sim)

  checkpoint(df, df_sim, df_b, df_output)

  #return df, df_b, df_output

if __name__ == "__main__":

  main(df, df_sim, df_b)

"""# Main Output"""

path = './Checkpoints/'
tuple_inputs = pickle.load(open(path + "ppi_output", 'rb'))
df = tuple_inputs[0]
df_sim = tuple_inputs[1]
df_b = tuple_inputs[2]
df_output = tuple_inputs[3]


"""# Anvil Connection

Private Key: https://63Q2A4ZEHPJO67CU.anvil.app/37CIZNUTZITSPS7HZ5PUV7J7
"""

anvil.server.connect("2PKDVT3KVG7CT3I3Y3CSUNRN-63Q2A4ZEHPJO67CU")



"""# PPI Predict"""

@anvil.server.callable
def ppi_predict(profile, playing_time, goals, assists, key_passes, completed_passes, success_ball, possesion_participation, touches, shots, shots_on_goal, crosses, turnover, recoveries, fouls, yellow_cards, red_cards, saves, clean_sheets, offsides, outcome):

  df_ = df_sim[['P-Profile', 'PT-PlayingTime', 'G-Goals', 'A-Assists',
       'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets',
       'O-Offsides', 'OUT-Outcomes', 'PPI']]
  
  df_.loc[len(df_.index)] = [profile, playing_time, goals, assists, key_passes, completed_passes, success_ball, possesion_participation, 
                                      touches, shots, shots_on_goal, crosses, turnover, recoveries, fouls, yellow_cards, red_cards, saves, clean_sheets, offsides, outcome, 0]

  df__ = df_
  df_ = df_.iloc[:-1 , :]                        
  #print(df_)         

  scaler = MinMaxScaler()
  path = './Checkpoints/'

  if(profile == 'Attacker'):

    X = df_[df_['P-Profile'] == 'Attacker'][['PT-PlayingTime', 'G-Goals', 'A-Assists',
       'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets',
       'O-Offsides', 'OUT-Outcomes']]
    X_scaled = scaler.fit_transform(X.values)
    y = df_[df_['P-Profile'] == 'Attacker']['PPI']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=4)
    lr = LinearRegression().fit(X_train.values, y_train.values)

    filename = 'ppi_model_attacker.sav'
    pickle.dump(lr, open(path + filename, 'wb'))

  elif(profile == 'Defender'):

    X = df_[df_['P-Profile'] == 'Defender'][['PT-PlayingTime', 'G-Goals', 'A-Assists',
       'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets',
       'O-Offsides', 'OUT-Outcomes']]
    X_scaled = scaler.fit_transform(X)
    y = df_[df_['P-Profile'] == 'Defender']['PPI']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=4)
    lr = LinearRegression().fit(X_train.values, y_train.values)

    filename = 'ppi_model_defender.sav'
    pickle.dump(lr, open(path + filename, 'wb'))

  elif(profile == 'Midfielder'):

    X = df_[df_['P-Profile'] == 'Midfielder'][['PT-PlayingTime', 'G-Goals', 'A-Assists',
       'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets',
       'O-Offsides', 'OUT-Outcomes']]
    X_scaled = scaler.fit_transform(X)
    y = df_[df_['P-Profile'] == 'Midfielder']['PPI']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=4)
    lr = LinearRegression().fit(X_train.values, y_train.values)

    filename = 'ppi_model_midfielder.sav'
    pickle.dump(lr, open(path + filename, 'wb'))

  else:

    X = df_[df_['P-Profile'] == 'Goalkeeper'][['PT-PlayingTime', 'G-Goals', 'A-Assists',
       'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets',
       'O-Offsides', 'OUT-Outcomes']]
    X_scaled = scaler.fit_transform(X)
    y = df_[df_['P-Profile'] == 'Goalkeeper']['PPI']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=4)
    lr = LinearRegression().fit(X_train.values, y_train.values)

    # save the model to disk
    filename = 'ppi_model_goalkeeper.sav'
    pickle.dump(lr, open(path + filename, 'wb'))

  #print(df__)
  df__scaled = scaler.fit_transform(df__[['PT-PlayingTime', 'G-Goals', 'A-Assists',
       'KP-KeyPasses', 'CP-CompletedPassees', 'SR-SuccessfulRatew/Ball',
       'PP-PossessionParticipation%', 'T-Touches', 'SH-Shots',
       'SG-ShotsonGoal', 'C-Crosses', 'TO-Turnover', 'R-Recoveries', 'F-Fouls',
       'YC-YellowCards', 'RC-RedCards', 'SV-Saves', 'CleanSheets',
       'O-Offsides', 'OUT-Outcomes']])
  
  #print(df__)
  input_values = df__scaled[df__scaled.shape[0]-1]
  print(input_values)  

  prediction = lr.predict([input_values])

  return round(prediction[0]*10, 2)


"""# Availability Forever"""

anvil.server.wait_forever()

"""# Tasks 

- Customize Logo & Colors
- Multiply by 10 
- Support in the rest 2-3 months

Very good work and great bussiness case interpretations, tested with the matchs data works perfect!! :)

"""
